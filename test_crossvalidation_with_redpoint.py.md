Ø­ØªÙ…Ø§Ù‹! Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ ÛŒÚ© Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ØŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ØŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ `test_crossvalidation_with_redpoint.py` Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù… Ú©Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø± GitHub Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø§Ø³Øª.

---

## ğŸ“Š Project Report: Tree Species Detection & Classification using Faster R-CNN with Dot-based Filtering

### ğŸ“ Script: `test_crossvalidation_with_redpoint.py`

**Last updated:** 2025-07-15

---

### ğŸ” Overview

This repository evaluates a fine-tuned [Faster R-CNN](https://arxiv.org/abs/1506.01497) model on **aerial images of dense forests** to classify individual trees by species.

The evaluation pipeline leverages **center-point (dot) annotations** as ground truth and uses **point-in-box logic** for filtering predictions. Classification performance is assessed using standard metrics such as **precision**, **recall**, and **F1-score**, derived via a **confusion matrix**.

---

### ğŸŒ² Task Description

The model performs:

* ğŸ¯ **Tree detection**: Locating individual trees in dense canopy
* ğŸ§¬ **Species classification**: Assigning a species class (1â€“5) to each detected tree

Ground truth consists of:

* `test_labels.csv`: True bounding boxes and species labels
* `dots_csv/*.csv`: Center-point annotations of trees (cx, cy)

---

### ğŸ§  Pipeline Summary

| Step                          | Description                                                                |
| ----------------------------- | -------------------------------------------------------------------------- |
| ğŸ–¼ï¸ Load test images          | Reads all test samples and their image filenames                           |
| ğŸ¤– Load model                 | Loads a pretrained Faster R-CNN model with custom head (5 species classes) |
| ğŸ” Predict bounding boxes     | Applies model to detect trees and predict class & confidence score         |
| ğŸ“ Filter with dot-points     | Keeps only boxes that **contain a GT point** and are **closest** to it     |
| ğŸ“¤ Export filtered boxes      | Saves final boxes to per-image CSVs and a merged global CSV                |
| ğŸ“Š Compute metrics            | Calculates confusion matrix, precision, recall, and F1-score               |
| ğŸ¨ Visualize confusion matrix | Plots confusion matrix using `seaborn`                                     |

---

### ğŸ“ Directory Structure

```bash
dataset/
â”œâ”€â”€ images/                    # Aerial RGB images
â”œâ”€â”€ test_labels.csv           # GT bounding boxes + labels
â”œâ”€â”€ dots_csv/*.csv            # GT dot (cx, cy) annotations per image
â”œâ”€â”€ checkpoints_cross/        # Saved model weights
â”œâ”€â”€ COMBINE_RESULT/
â”‚   â”œâ”€â”€ predicted_boxes/      # Raw model outputs
â”‚   â”œâ”€â”€ filtered_predicted_dots/  # Filtered results using point-in-box logic
â”‚   â”œâ”€â”€ merged_predictions.csv    # Combined predictions
â”‚   â””â”€â”€ classification_metrics.csv  # Precision, recall, F1
```

---

### âš™ï¸ Step-by-Step Workflow

1. **Image & Dot Loader**

   * Loads each test image
   * Reads corresponding center-points from `.csv` in `dots_csv`

2. **Model Inference**

   * Loads a `.pth` checkpoint from `checkpoints_cross`
   * For each image:

     * Detects bounding boxes, class labels, and confidence scores

3. **Point-in-Box Filtering**

   * For each `(cx, cy)` GT point:

     * Searches all predicted boxes that contain the point
     * Selects the box with **highest score and closest center**
   * Removes duplicate or overlapping predictions

4. **Export & Merge**

   * Saves filtered boxes to:

     * Per-image CSV files (`filtered_predicted_dots`)
     * Global merged CSV (`merged_predictions.csv`)

5. **Evaluation**

   * Compares predicted class vs. true class from `test_labels.csv`
   * Computes:

     * ğŸ“ Precision (macro)
     * ğŸ§² Recall (macro)
     * ğŸ§® F1-score (macro)
   * Confusion matrix is computed and visualized

---

### ğŸ“Š Example Output

```txt
Precision: 0.90
Recall:    0.88
F1 Score:  0.89
```

<p align="center">
  <img src="assets/confusion_matrix_example.png" width="600"/>
</p>

---

### âœ… Key Characteristics

* ğŸ“ **Dot-based filtering**: Boxes are retained **only** if they cover a GT point
* ğŸ” **No use of IoU**: IoU is **not computed** in this script; matching is spatial (point-in-box)
* ğŸ“š **Dual GTs used**:

  * Dots for localization
  * Boxes for classification
* ğŸ“ˆ **Confusion matrix** provides full insight into classification accuracy per species

---

### ğŸ’¾ Output Files

| File                            | Description                                |
| ------------------------------- | ------------------------------------------ |
| `merged_predictions.csv`        | Final filtered predictions                 |
| `classification_metrics.csv`    | Precision, recall, F1                      |
| `filtered_predicted_dots/*.csv` | Per-image predictions after filtering      |
| `confusion matrix image`        | Heatmap-style image of prediction accuracy |

---

### ğŸ”§ Requirements

```bash
torch
torchvision
pandas
numpy
scikit-learn
matplotlib
seaborn
tqdm
```

---

### ğŸ“Œ Notes

* Assumes test set is **fixed**, and model checkpoint is trained externally.
* Designed for **dense forests** where multiple trees occur in close proximity.
* Custom logic avoids overlapping predictions by choosing highest-score + shortest-distance box.

---

### ğŸš€ Suggested Improvements

* Add IoU filtering for stricter box validation
* Visualize per-class detection success
* Include PR curves (per class) and mAP metric

---

Ø§Ú¯Ø± Ø®ÙˆØ§Ø³ØªÛŒ Ù†Ø³Ø®Ù‡ ÙØ§Ø±Ø³ÛŒ Ù‡Ù… Ø¢Ù…Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù… ğŸŒ±
Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ ØªÙˆ Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ ÛŒÙ‡ `README.md` Ú©Ø§Ù…Ù„ Ù‡Ù… Ø¨Ø±Ø§Øª ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ù…ØŸ
