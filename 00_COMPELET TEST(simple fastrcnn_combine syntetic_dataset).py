import os
import csv
import math
import pandas as pd
import torch
import torchvision
from PIL import Image
from torch.utils.data import DataLoader
from torchvision.transforms import functional as F
from tqdm import tqdm
import seaborn as sns

import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score
from confusion_matrix import compute_confusion_matrix
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª CUDA
CUDA_LAUNCH_BLOCKING = 1
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print("ğŸš€ Device:", device)

# Ù…Ø³ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
root_dir = r"E:\FASTRCNN\FASTRCNN\dataset\00_source_code_data_ADDING BEST 0.95 TO TRAIN AND VAL\step_0_masked_with redpoint"
combine_result_dir = os.path.join(root_dir, "checkpoints_batch16", "COMBINE_RESULT")

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
os.makedirs(combine_result_dir, exist_ok=True)

# ---------------------------- 1ï¸âƒ£ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª ----------------------------
class trDataset(torch.utils.data.Dataset):
    def __init__(self, root, phase):
        self.root = root
        self.phase = phase
        self.targets = pd.read_csv(os.path.join(root, f'{phase}_labels.csv'))
        self.imgs = self.targets['filename'].astype(str)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root, r'\FASTRCNN\FASTRCNN\dataset\00_source_code_data_ADDING BEST 0.95 TO TRAIN AND VAL', 'images&DOT&dot', self.imgs[idx])
        img = Image.open(img_path).convert('RGB')
        img = F.to_tensor(img)

        filename = self.imgs[idx]
        return img, filename

    def __len__(self):
        return len(self.imgs)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡
test_dataset = trDataset(root_dir, 'test')
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# ---------------------------- 2ï¸âƒ£ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ----------------------------
output_folder = os.path.join(combine_result_dir, "predicted_boxes")
os.makedirs(output_folder, exist_ok=True)
print(f"ğŸ“‚ Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø¯Ù„: {output_folder}")

model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights="DEFAULT")
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(1024, 5)
model.load_state_dict(torch.load(os.path.join(root_dir, r"E:\FASTRCNN\FASTRCNN\dataset\00_source_code_data_ADDING BEST 0.95 TO TRAIN AND VAL\step_0_masked_with redpoint\checkpoints_batch16", "best_model_7.pth")))
model.to(device)

model.eval()
print("ğŸ” Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ø§ Ù…Ø¯Ù„...")


with torch.no_grad():
    for images, filenames in tqdm(test_loader, desc="ğŸ“¸ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±"):
        images = [image.to(device) for image in images]
        out = model(images)

        for i, (filename, prediction) in enumerate(zip(filenames, out)):


            # 2ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ù‡â€ŒØ¯Ø±Ø³ØªÛŒ
            if isinstance(filename, list) or isinstance(filename, tuple):
                filename_str = filename[0]  # Ø§Ú¯Ø± Ù„ÛŒØ³Øª ÛŒØ§ ØªØ§Ù¾Ù„ Ø§Ø³ØªØŒ Ù…Ù‚Ø¯Ø§Ø± Ø§ÙˆÙ„ Ø±Ø§ Ø¨Ú¯ÛŒØ±
            else:
                filename_str = str(filename)  # Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø¢Ù† Ø±Ø§ Ø±Ø´ØªÙ‡ Ú©Ù†

            # 3ï¸âƒ£ Ø­Ø°Ù Ù…Ø³ÛŒØ± Ùˆ Ù¾Ø³ÙˆÙ†Ø¯ `.jpg` ÛŒØ§ `.png` Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù…Ù‚Ø¯Ø§Ø±
            filename_str = os.path.basename(str(filename_str))  # ÙÙ‚Ø· Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ú¯ÛŒØ±
            filename_str = os.path.splitext(filename_str)[0]  # Ù¾Ø³ÙˆÙ†Ø¯ Ø±Ø§ Ø­Ø°Ù Ú©Ù†



            # 5ï¸âƒ£ Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ CSV
            output_csv_file = os.path.join(output_folder, f"{filename_str}.csv")

            # 6ï¸âƒ£ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø¯Ù„
            boxes = prediction['boxes'].cpu().numpy()
            labels = prediction['labels'].cpu().numpy()
            scores = prediction['scores'].cpu().numpy()

            # 7ï¸âƒ£ Ø³Ø§Ø®ØªÙ† Ù„ÛŒØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            data = [
                [filename_str, label, int(xmin), int(ymin), int(xmax), int(ymax), float(score)]
                for box, label, score in zip(boxes, labels, scores)
                for xmin, ymin, xmax, ymax in [box]
            ]

            # 8ï¸âƒ£ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            df = pd.DataFrame(data, columns=['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax', 'score'])

            # 9ï¸âƒ£ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ `filename` Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† `str` Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯
            df['filename'] = df['filename'].astype(str)

            # ğŸ”Ÿ Ø°Ø®ÛŒØ±Ù‡ CSV Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù†Ø§Ù… ÙØ§ÛŒÙ„
            df.to_csv(output_csv_file, index=False)

print("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

# ---------------------------- 3ï¸âƒ£ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø§Ú©Ø³â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² ----------------------------
filtered_dots_folder = os.path.join(combine_result_dir, "filtered_predicted_dots")
os.makedirs(filtered_dots_folder, exist_ok=True)

points_folder = os.path.join(root_dir, r"E:\FASTRCNN\FASTRCNN\dataset\00_source_code_data_ADDING BEST 0.95 TO TRAIN AND VAL", "dots_csv")
print("points_folder",points_folder)
def calculate_distance(point, box_center):
    return math.sqrt((point[0] - box_center[0])**2 + (point[1] - box_center[1])**2)

def process_files(boxes_file, points_file, output_file):
    boxes_df = pd.read_csv(boxes_file)
    points_df = pd.read_csv(points_file)

    output_rows = []
    for _, point_row in points_df.iterrows():
        cx, cy = point_row['cx'], point_row['cy']

        best_box = None
        best_score = -1
        min_distance = float('inf')

        for _, box_row in boxes_df.iterrows():
            xmin, ymin, xmax, ymax = box_row['xmin'], box_row['ymin'], box_row['xmax'], box_row['ymax']
            score = box_row['score']

            if xmin <= cx <= xmax and ymin <= cy <= ymax:
                box_center = ((xmax + xmin) / 2, (ymax + ymin) / 2)
                distance = calculate_distance((cx, cy), box_center)

                if score > best_score or (score == best_score and distance < min_distance):
                    best_box = box_row
                    best_score = score
                    min_distance = distance

        if best_box is not None:
            output_rows.append(best_box.to_dict())

    output_df = pd.DataFrame(output_rows)
    output_df.to_csv(output_file, index=False)

for points_filename in tqdm(os.listdir(points_folder), desc="ğŸ“‚ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø§Ø·"):
    if points_filename.endswith(".csv"):
        boxes_file = os.path.join(output_folder, points_filename)
        points_file = os.path.join(points_folder, points_filename)
        output_file = os.path.join(filtered_dots_folder, points_filename)

        if os.path.exists(boxes_file) and os.path.exists(points_file):
            process_files(boxes_file, points_file, output_file)

print("âœ… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ù‚Ø§Ø· Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")

# ---------------------------- 4ï¸âƒ£ ØªØ¬Ù…ÛŒØ¹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV ----------------------------
# ---------------------------- 4ï¸âƒ£ ØªØ¬Ù…ÛŒØ¹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV ----------------------------
merged_file_path = os.path.join(combine_result_dir, "merged_predictions.csv")

merged_data = []
for csv_file in tqdm(os.listdir(filtered_dots_folder), desc="ğŸ”„ ØªØ¬Ù…ÛŒØ¹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§"):
    if csv_file.endswith(".csv"):
        file_path = os.path.join(filtered_dots_folder, csv_file)
        df = pd.read_csv(file_path)

        # Ø§ØµÙ„Ø§Ø­ Ù†Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: Ø­Ø°Ù ".0" Ùˆ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù¾Ø³ÙˆÙ†Ø¯ ".tif"
        df['filename'] = df['filename'].astype(str).str.replace('.0', '', regex=False) + ".tif"

        # Ø­Ø°Ù Ø³ØªÙˆÙ† "score" Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        if 'score' in df.columns:
            df = df.drop(columns=['score'])

        merged_data.append(df)

final_df = pd.concat(merged_data, ignore_index=True)
final_df.to_csv(merged_file_path, index=False)

print(f"âœ… ÙØ§ÛŒÙ„ ØªØ¬Ù…ÛŒØ¹ Ø´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {merged_file_path}")




# ØªÙ†Ø¸ÛŒÙ…Ø§Øª CUDA
CUDA_LAUNCH_BLOCKING = 1
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print("ğŸš€ Device:", device)

# Ù…Ø³ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
root_dir = r"E:\FASTRCNN\FASTRCNN\dataset\00_source_code_data_ADDING BEST 0.95 TO TRAIN AND VAL\step_0_masked_with redpoint"
combine_result_dir = os.path.join(root_dir, "checkpoints_batch16", "COMBINE_RESULT")

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
os.makedirs(combine_result_dir, exist_ok=True)

# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
merged_file_path = os.path.join(combine_result_dir, "merged_predictions.csv")
test_labels_path = os.path.join(root_dir, "test_labels.csv")

# ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù†ÙÛŒÙˆØ´Ù† Ù…Ø§ØªØ±ÛŒØ³
conf_matrix, true_labels, pred_labels = compute_confusion_matrix(test_labels_path, merged_file_path)

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
precision = precision_score(true_labels, pred_labels, average='macro')
recall = recall_score(true_labels, pred_labels, average='macro')
f1 = f1_score(true_labels, pred_labels, average='macro')

# Ù†Ù…Ø§ÛŒØ´ Ù…Ø§ØªØ±ÛŒØ³ Ú©Ø§Ù†ÙÛŒÙˆØ´Ù†
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix (5x5)")
plt.show()

# Ù†Ù…Ø§ÛŒØ´ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ CSV
metrics_df = pd.DataFrame({
    "Metric": ["Precision", "Recall", "F1 Score"],
    "Value": [precision, recall, f1]
})
metrics_df.to_csv(os.path.join(combine_result_dir, "classification_metrics.csv"), index=False)
print("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯.")
